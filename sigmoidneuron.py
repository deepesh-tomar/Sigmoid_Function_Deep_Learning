# -*- coding: utf-8 -*-
"""SigmoidNeuron.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13yMavqfb_97wN-6OZUgRJj5t-Tv8v-LT

#Plotting Sigmoid Function
"""

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits import mplot3d
import matplotlib.colors
import pandas  as pd
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error
from tqdm import tqdm_notebook

"""#$S_{w,b}(x) = \frac{1}{1 + e^{-(wx + b)}}$"""

def sigmoid(x ,w, b):
  return 1/(1+ np.exp(-(w*x + b)))

sigmoid(1, 0.5, 0)

w = -1.6  #@param {type: "slider", min: -2, max: 2, step: 0.1}
b = -1.1   #@param {type: "slider", min: -2, max: 2, step: 0.1}
X = np.linspace(-10, 10, 100)
Y = sigmoid(X, w, b)

plt.plot(X, Y)
plt.show()

"""#$S_(w_1, w_2, b)(x_1, x_2) = \frac{1}{1+e^{-(W_1x_1 + W_2x_2 + b)}}$"""

def sigmoid_2d(x1, x2, w1, w2, b):
  return 1/(1+ np.exp(-(w1*x1 + w2*x2 +b)))

sigmoid_2d(1, 0, 0.5, 0 , 0)



X1 = np.linspace(-10, 10, 100)
X2 = np.linspace(-10, 10, 100)
w1 = 0.5
w2 = 0.5
b = 0
XX1, XX2 = np.meshgrid(X1, X2)

Y = sigmoid_2d(XX1, XX2, w1, w2, b)

my_cmap = matplotlib.colors.LinearSegmentedColormap.from_list("", ["red","yellow","green"])

plt.contourf(XX1, XX2, Y, cmap = my_cmap, alpha = 0.9)
plt.grid(linestyle = '-', color = 'black', alpha = 0.2)
plt.show()

fig = plt.figure()
ax = plt.axes(projection = '3d')
ax.plot_surface(XX1, XX2, Y, cmap='viridis')
ax.set_xlabel('x1')
ax.set_ylabel('x2')
ax.set_zlabel('y')

ax.view_init(30, 180)

"""#Compute loss for given dataset"""

w_unknown = 0.5
b_unknown = 0.25
X = np.random.random(25) * 20 -10
Y = sigmoid(X, w_unknown, b_unknown)

plt.plot(X, Y, '*')
plt.show()

def calculate_loss(X, Y, w_est, b_est):
  loss = 0
  for x, y in zip(X, Y):
    loss += (y - sigmoid(x, w_est, b_est))**2
  return loss

W = np.linspace(0, 2, 101)
B = np.linspace(-1, 1, 101)

WW, BB = np.meshgrid(W, B)
Loss = np.zeros(WW.shape)

for i in range(WW.shape[0]):
  for j in range(WW.shape[1]):
    Loss[i, j] = calculate_loss(X, Y, WW[i, j], BB[i, j])

fig = plt.figure()
ax = plt.axes(projection = '3d')
ax.plot_surface(WW, BB, Loss, cmap='viridis')
ax.set_xlabel('w')
ax.set_ylabel('b')
ax.set_zlabel('loss')

ax.view_init(20, 50)

ij =np.argmin(Loss)
i = int(np.float(ij/Loss.shape[1]))
j = int(ij - i * Loss.shape[1])

print(i , j)

print(WW[i,j], BB[i, j])

"""#Class for Sigmoid Neuron"""

class SigmoidNeuron:

  def __init__(self):
    self.w = None
    self.b = None
  
  def perceptron(self, x):
    return np.dot(x, self.w.T) + self.b

  def sigmoid(self, x):
    return 1.0/(1.0 + np.exp(-x))

  def grad_w(self, x, y):
    y_pred = self.sigmoid(self.perceptron(x))
    return (y_pred - y) * y_pred * (1 - y_pred) * x
  
  def grad_b(self, x, y):
    y_pred = self.sigmoid(self.perceptron(x))
    return (y_pred - y) * y_pred * (1 - y_pred) 
  
  def fit(self, X , Y, epochs = 1, learning_rate = 1, initialise = True, display_loss=False):
    #initialise w,b
    if initialise:
      self.w = np.random.randn(1, X.shape[1])
      self.b = 0
    
    if display_loss:
      loss = {}

    for i in tqdm_notebook(range(epochs), total= epochs, unit="epochs"):
      dw = 0
      db = 0
      for x, y in zip(X, Y):
        dw += self.grad_w(x, y)
        db += self.grad_b(x, y)
      self.w -= learning_rate * dw
      self.b -= learning_rate * db

      if display_loss:
        Y_pred = self.sigmoid(self.perceptron(X))
        loss[i] = mean_squared_error(Y_pred, Y)
    
    if display_loss:
      plt.plot(list(loss.values()))
      plt.xlabel('Epochs')
      plt.ylabel('Mean Squared Error')
      plt.grid(linestyle = '-', color = 'black')
      plt.show()


  def predict(self, X):
    Y_pred = []
    for x in X:
      y_pred = self.sigmoid(self.perceptron(x))
      Y_pred.append(y_pred)
    return np.array(Y_pred)

"""#Fit for toy data"""

X = np.asarray([[2.5, 2.5],[4, -1], [1, -4], [-3, 1.25], [-2,-4], [1, 5]])
Y = [1, 1, 1, 0, 0, 0]

sn = SigmoidNeuron()
sn.fit(X, Y, 1, 0.25, True)

def plot_sn(X, Y, sn, ax):
  X1 = np.linspace(-10, 10, 100)
  X2 = np.linspace(-10, 10, 100)
  XX1, XX2, = np.meshgrid(X1, X2)
  YY = np.zeros(XX1.shape)
  for i in range(X2.size):
    for j in range(X1.size):
      val = np.asarray([X1[j], X2[i]])
      YY[i, j] = sn.sigmoid(sn.perceptron(val))
  my_cmap = matplotlib.colors.LinearSegmentedColormap.from_list("", ["red","yellow","green"])
  ax.contourf(XX1, XX2, YY, cmap=my_cmap)
  ax.grid(linestyle = '-', color = 'black')
  ax.scatter(X[:, 0], X[:, 1], c=Y)
  ax.plot()

sn.fit(X, Y, 1, 0.5, True)
N = 50
plt.figure(figsize = (10, N*5))
for i in range(N):
  print(sn.w, sn.b)
  ax = plt.subplot(N, 1, i + 1)
  plot_sn(X, Y, sn, ax)
  sn.fit(X, Y, 1, 0.5, False)

"""#Live plotting"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
from matplotlib import animation, rc
from IPython.display import HTML

# First set up the figure, the axis, and the plot element we want to animate
fig, ax = plt.subplots()

ax.set_xlim((0, 10))
ax.set_ylim((-10, 10 ))

line, = ax.plot([], [], lw=2)

# animation function. This is called sequentially
def animate(i):
    x = X1
    y = X2
    line.set_data(x, y)
    return (line,)

# call the animator. blit=True means only re-draw the parts that have changed.
anim = animation.FuncAnimation(fig, animate, frames=100, interval=100, blit=True)

HTML(anim.to_html5_video())



"""#Loading Data"""



data = pd.read_csv('/content/drive/My Drive/mobile_cleaned-1551253091700.csv')

data.head()

data.shape

X = data.drop('Rating', axis = 1)

Y = data['Rating'].values

Y

threshold = 4.2
data['class'] = (data['Rating'] >= threshold).astype(np.int)

data['class'].value_counts(normalize=True)

Y_binarised = data['class'].values

"""##Standardisation"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 0, stratify = Y_binarised)

print(X_train.shape, X_test.shape)

scaler = StandardScaler()

X_scaled_train = scaler.fit_transform(X_train)
X_scaled_test = scaler.transform(X_test)

minmax_scaler = MinMaxScaler()

Y_scaled_train = minmax_scaler.fit_transform(Y_train.reshape(-1, 1))

np.min(Y_scaled_train)

Y_scaled_test = minmax_scaler.fit_transform(Y_test.reshape(-1, 1))

scaled_threshold = list(minmax_scaler.transform(np.array([threshold]).reshape(1, -1)))[0][0]

scaled_threshold

Y_binarised_train = (Y_scaled_train > scaled_threshold).astype("int").ravel()

Y_binarised_test = (Y_scaled_test > scaled_threshold).astype("int").ravel()

"""#Train on Real Data"""

sn = SigmoidNeuron()

sn.fit(X_scaled_train, Y_scaled_train, epochs=1000, learning_rate=0.01, display_loss=True)

Y_pred_train = sn.predict(X_scaled_train)
Y_pred_test = sn.predict(X_scaled_test)

Y_pred_binarised_train = (Y_pred_train > scaled_threshold).astype("int").ravel()
Y_pred_binarised_test = (Y_pred_test > scaled_threshold).astype("int").ravel()

accuracy_train = accuracy_score(Y_pred_binarised_train, Y_binarised_train)
accuracy_test = accuracy_score(Y_pred_binarised_test, Y_binarised_test)

print(accuracy_train *100, accuracy_test*100)



